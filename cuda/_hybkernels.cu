//
// auto-generated by op2.py
//

//header
#ifdef GPUPASS
#define op_par_loop_initialize_variables_kernel op_par_loop_initialize_variables_kernel_gpu
#define op_par_loop_zero_5d_array_kernel op_par_loop_zero_5d_array_kernel_gpu
#define op_par_loop_zero_1d_array_kernel op_par_loop_zero_1d_array_kernel_gpu
#define op_par_loop_calculate_cell_volumes op_par_loop_calculate_cell_volumes_gpu
#define op_par_loop_dampen_ewt op_par_loop_dampen_ewt_gpu
#define op_par_loop_copy_double_kernel op_par_loop_copy_double_kernel_gpu
#define op_par_loop_calculate_dt_kernel op_par_loop_calculate_dt_kernel_gpu
#define op_par_loop_get_min_dt_kernel op_par_loop_get_min_dt_kernel_gpu
#define op_par_loop_compute_step_factor_kernel op_par_loop_compute_step_factor_kernel_gpu
#define op_par_loop_compute_flux_edge_kernel op_par_loop_compute_flux_edge_kernel_gpu
#define op_par_loop_compute_bnd_node_flux_kernel op_par_loop_compute_bnd_node_flux_kernel_gpu
#define op_par_loop_time_step_kernel op_par_loop_time_step_kernel_gpu
#define op_par_loop_indirect_rw_kernel op_par_loop_indirect_rw_kernel_gpu
#define op_par_loop_residual_kernel op_par_loop_residual_kernel_gpu
#define op_par_loop_calc_rms_kernel op_par_loop_calc_rms_kernel_gpu
#define op_par_loop_count_bad_vals op_par_loop_count_bad_vals_gpu
#define op_par_loop_up_pre_kernel op_par_loop_up_pre_kernel_gpu
#define op_par_loop_up_kernel op_par_loop_up_kernel_gpu
#define op_par_loop_up_post_kernel op_par_loop_up_post_kernel_gpu
#define op_par_loop_down_v2_kernel_pre op_par_loop_down_v2_kernel_pre_gpu
#define op_par_loop_down_v2_kernel op_par_loop_down_v2_kernel_gpu
#define op_par_loop_down_v2_kernel_post op_par_loop_down_v2_kernel_post_gpu
#define op_par_loop_down_kernel op_par_loop_down_kernel_gpu
#define op_par_loop_identify_differences op_par_loop_identify_differences_gpu
#define op_par_loop_count_non_zeros op_par_loop_count_non_zeros_gpu
#include "_kernels.cu"
#undef op_par_loop_initialize_variables_kernel
#undef op_par_loop_zero_5d_array_kernel
#undef op_par_loop_zero_1d_array_kernel
#undef op_par_loop_calculate_cell_volumes
#undef op_par_loop_dampen_ewt
#undef op_par_loop_copy_double_kernel
#undef op_par_loop_calculate_dt_kernel
#undef op_par_loop_get_min_dt_kernel
#undef op_par_loop_compute_step_factor_kernel
#undef op_par_loop_compute_flux_edge_kernel
#undef op_par_loop_compute_bnd_node_flux_kernel
#undef op_par_loop_time_step_kernel
#undef op_par_loop_indirect_rw_kernel
#undef op_par_loop_residual_kernel
#undef op_par_loop_calc_rms_kernel
#undef op_par_loop_count_bad_vals
#undef op_par_loop_up_pre_kernel
#undef op_par_loop_up_kernel
#undef op_par_loop_up_post_kernel
#undef op_par_loop_down_v2_kernel_pre
#undef op_par_loop_down_v2_kernel
#undef op_par_loop_down_v2_kernel_post
#undef op_par_loop_down_kernel
#undef op_par_loop_identify_differences
#undef op_par_loop_count_non_zeros
#else
#define op_par_loop_initialize_variables_kernel op_par_loop_initialize_variables_kernel_cpu
#define op_par_loop_zero_5d_array_kernel op_par_loop_zero_5d_array_kernel_cpu
#define op_par_loop_zero_1d_array_kernel op_par_loop_zero_1d_array_kernel_cpu
#define op_par_loop_calculate_cell_volumes op_par_loop_calculate_cell_volumes_cpu
#define op_par_loop_dampen_ewt op_par_loop_dampen_ewt_cpu
#define op_par_loop_copy_double_kernel op_par_loop_copy_double_kernel_cpu
#define op_par_loop_calculate_dt_kernel op_par_loop_calculate_dt_kernel_cpu
#define op_par_loop_get_min_dt_kernel op_par_loop_get_min_dt_kernel_cpu
#define op_par_loop_compute_step_factor_kernel op_par_loop_compute_step_factor_kernel_cpu
#define op_par_loop_compute_flux_edge_kernel op_par_loop_compute_flux_edge_kernel_cpu
#define op_par_loop_compute_bnd_node_flux_kernel op_par_loop_compute_bnd_node_flux_kernel_cpu
#define op_par_loop_time_step_kernel op_par_loop_time_step_kernel_cpu
#define op_par_loop_indirect_rw_kernel op_par_loop_indirect_rw_kernel_cpu
#define op_par_loop_residual_kernel op_par_loop_residual_kernel_cpu
#define op_par_loop_calc_rms_kernel op_par_loop_calc_rms_kernel_cpu
#define op_par_loop_count_bad_vals op_par_loop_count_bad_vals_cpu
#define op_par_loop_up_pre_kernel op_par_loop_up_pre_kernel_cpu
#define op_par_loop_up_kernel op_par_loop_up_kernel_cpu
#define op_par_loop_up_post_kernel op_par_loop_up_post_kernel_cpu
#define op_par_loop_down_v2_kernel_pre op_par_loop_down_v2_kernel_pre_cpu
#define op_par_loop_down_v2_kernel op_par_loop_down_v2_kernel_cpu
#define op_par_loop_down_v2_kernel_post op_par_loop_down_v2_kernel_post_cpu
#define op_par_loop_down_kernel op_par_loop_down_kernel_cpu
#define op_par_loop_identify_differences op_par_loop_identify_differences_cpu
#define op_par_loop_count_non_zeros op_par_loop_count_non_zeros_cpu
#include "../openmp/_kernels.cpp"
#undef op_par_loop_initialize_variables_kernel
#undef op_par_loop_zero_5d_array_kernel
#undef op_par_loop_zero_1d_array_kernel
#undef op_par_loop_calculate_cell_volumes
#undef op_par_loop_dampen_ewt
#undef op_par_loop_copy_double_kernel
#undef op_par_loop_calculate_dt_kernel
#undef op_par_loop_get_min_dt_kernel
#undef op_par_loop_compute_step_factor_kernel
#undef op_par_loop_compute_flux_edge_kernel
#undef op_par_loop_compute_bnd_node_flux_kernel
#undef op_par_loop_time_step_kernel
#undef op_par_loop_indirect_rw_kernel
#undef op_par_loop_residual_kernel
#undef op_par_loop_calc_rms_kernel
#undef op_par_loop_count_bad_vals
#undef op_par_loop_up_pre_kernel
#undef op_par_loop_up_kernel
#undef op_par_loop_up_post_kernel
#undef op_par_loop_down_v2_kernel_pre
#undef op_par_loop_down_v2_kernel
#undef op_par_loop_down_v2_kernel_post
#undef op_par_loop_down_kernel
#undef op_par_loop_identify_differences
#undef op_par_loop_count_non_zeros

//user kernel files

void op_par_loop_initialize_variables_kernel_gpu(char const *name, op_set set,
  op_arg arg0);

//GPU host stub function
#if OP_HYBRID_GPU
void op_par_loop_initialize_variables_kernel(char const *name, op_set set,
  op_arg arg0){

  if (OP_hybrid_gpu) {
    op_par_loop_initialize_variables_kernel_gpu(name, set,
      arg0);

    }else{
    op_par_loop_initialize_variables_kernel_cpu(name, set,
      arg0);

  }
}
#else
void op_par_loop_initialize_variables_kernel(char const *name, op_set set,
  op_arg arg0){

  op_par_loop_initialize_variables_kernel_gpu(name, set,
    arg0);

  }
#endif //OP_HYBRID_GPU

void op_par_loop_zero_5d_array_kernel_gpu(char const *name, op_set set,
  op_arg arg0);

//GPU host stub function
#if OP_HYBRID_GPU
void op_par_loop_zero_5d_array_kernel(char const *name, op_set set,
  op_arg arg0){

  if (OP_hybrid_gpu) {
    op_par_loop_zero_5d_array_kernel_gpu(name, set,
      arg0);

    }else{
    op_par_loop_zero_5d_array_kernel_cpu(name, set,
      arg0);

  }
}
#else
void op_par_loop_zero_5d_array_kernel(char const *name, op_set set,
  op_arg arg0){

  op_par_loop_zero_5d_array_kernel_gpu(name, set,
    arg0);

  }
#endif //OP_HYBRID_GPU

void op_par_loop_zero_1d_array_kernel_gpu(char const *name, op_set set,
  op_arg arg0);

//GPU host stub function
#if OP_HYBRID_GPU
void op_par_loop_zero_1d_array_kernel(char const *name, op_set set,
  op_arg arg0){

  if (OP_hybrid_gpu) {
    op_par_loop_zero_1d_array_kernel_gpu(name, set,
      arg0);

    }else{
    op_par_loop_zero_1d_array_kernel_cpu(name, set,
      arg0);

  }
}
#else
void op_par_loop_zero_1d_array_kernel(char const *name, op_set set,
  op_arg arg0){

  op_par_loop_zero_1d_array_kernel_gpu(name, set,
    arg0);

  }
#endif //OP_HYBRID_GPU

void op_par_loop_calculate_cell_volumes_gpu(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3,
  op_arg arg4);

//GPU host stub function
#if OP_HYBRID_GPU
void op_par_loop_calculate_cell_volumes(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3,
  op_arg arg4){

  if (OP_hybrid_gpu) {
    op_par_loop_calculate_cell_volumes_gpu(name, set,
      arg0,
      arg1,
      arg2,
      arg3,
      arg4);

    }else{
    op_par_loop_calculate_cell_volumes_cpu(name, set,
      arg0,
      arg1,
      arg2,
      arg3,
      arg4);

  }
}
#else
void op_par_loop_calculate_cell_volumes(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3,
  op_arg arg4){

  op_par_loop_calculate_cell_volumes_gpu(name, set,
    arg0,
    arg1,
    arg2,
    arg3,
    arg4);

  }
#endif //OP_HYBRID_GPU

void op_par_loop_dampen_ewt_gpu(char const *name, op_set set,
  op_arg arg0);

//GPU host stub function
#if OP_HYBRID_GPU
void op_par_loop_dampen_ewt(char const *name, op_set set,
  op_arg arg0){

  if (OP_hybrid_gpu) {
    op_par_loop_dampen_ewt_gpu(name, set,
      arg0);

    }else{
    op_par_loop_dampen_ewt_cpu(name, set,
      arg0);

  }
}
#else
void op_par_loop_dampen_ewt(char const *name, op_set set,
  op_arg arg0){

  op_par_loop_dampen_ewt_gpu(name, set,
    arg0);

  }
#endif //OP_HYBRID_GPU

void op_par_loop_copy_double_kernel_gpu(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1);

//GPU host stub function
#if OP_HYBRID_GPU
void op_par_loop_copy_double_kernel(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1){

  if (OP_hybrid_gpu) {
    op_par_loop_copy_double_kernel_gpu(name, set,
      arg0,
      arg1);

    }else{
    op_par_loop_copy_double_kernel_cpu(name, set,
      arg0,
      arg1);

  }
}
#else
void op_par_loop_copy_double_kernel(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1){

  op_par_loop_copy_double_kernel_gpu(name, set,
    arg0,
    arg1);

  }
#endif //OP_HYBRID_GPU

void op_par_loop_calculate_dt_kernel_gpu(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2);

//GPU host stub function
#if OP_HYBRID_GPU
void op_par_loop_calculate_dt_kernel(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2){

  if (OP_hybrid_gpu) {
    op_par_loop_calculate_dt_kernel_gpu(name, set,
      arg0,
      arg1,
      arg2);

    }else{
    op_par_loop_calculate_dt_kernel_cpu(name, set,
      arg0,
      arg1,
      arg2);

  }
}
#else
void op_par_loop_calculate_dt_kernel(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2){

  op_par_loop_calculate_dt_kernel_gpu(name, set,
    arg0,
    arg1,
    arg2);

  }
#endif //OP_HYBRID_GPU

void op_par_loop_get_min_dt_kernel_gpu(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1);

//GPU host stub function
#if OP_HYBRID_GPU
void op_par_loop_get_min_dt_kernel(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1){

  if (OP_hybrid_gpu) {
    op_par_loop_get_min_dt_kernel_gpu(name, set,
      arg0,
      arg1);

    }else{
    op_par_loop_get_min_dt_kernel_cpu(name, set,
      arg0,
      arg1);

  }
}
#else
void op_par_loop_get_min_dt_kernel(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1){

  op_par_loop_get_min_dt_kernel_gpu(name, set,
    arg0,
    arg1);

  }
#endif //OP_HYBRID_GPU

void op_par_loop_compute_step_factor_kernel_gpu(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3);

//GPU host stub function
#if OP_HYBRID_GPU
void op_par_loop_compute_step_factor_kernel(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3){

  if (OP_hybrid_gpu) {
    op_par_loop_compute_step_factor_kernel_gpu(name, set,
      arg0,
      arg1,
      arg2,
      arg3);

    }else{
    op_par_loop_compute_step_factor_kernel_cpu(name, set,
      arg0,
      arg1,
      arg2,
      arg3);

  }
}
#else
void op_par_loop_compute_step_factor_kernel(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3){

  op_par_loop_compute_step_factor_kernel_gpu(name, set,
    arg0,
    arg1,
    arg2,
    arg3);

  }
#endif //OP_HYBRID_GPU

void op_par_loop_compute_flux_edge_kernel_gpu(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3,
  op_arg arg4);

//GPU host stub function
#if OP_HYBRID_GPU
void op_par_loop_compute_flux_edge_kernel(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3,
  op_arg arg4){

  if (OP_hybrid_gpu) {
    op_par_loop_compute_flux_edge_kernel_gpu(name, set,
      arg0,
      arg1,
      arg2,
      arg3,
      arg4);

    }else{
    op_par_loop_compute_flux_edge_kernel_cpu(name, set,
      arg0,
      arg1,
      arg2,
      arg3,
      arg4);

  }
}
#else
void op_par_loop_compute_flux_edge_kernel(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3,
  op_arg arg4){

  op_par_loop_compute_flux_edge_kernel_gpu(name, set,
    arg0,
    arg1,
    arg2,
    arg3,
    arg4);

  }
#endif //OP_HYBRID_GPU

void op_par_loop_compute_bnd_node_flux_kernel_gpu(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3);

//GPU host stub function
#if OP_HYBRID_GPU
void op_par_loop_compute_bnd_node_flux_kernel(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3){

  if (OP_hybrid_gpu) {
    op_par_loop_compute_bnd_node_flux_kernel_gpu(name, set,
      arg0,
      arg1,
      arg2,
      arg3);

    }else{
    op_par_loop_compute_bnd_node_flux_kernel_cpu(name, set,
      arg0,
      arg1,
      arg2,
      arg3);

  }
}
#else
void op_par_loop_compute_bnd_node_flux_kernel(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3){

  op_par_loop_compute_bnd_node_flux_kernel_gpu(name, set,
    arg0,
    arg1,
    arg2,
    arg3);

  }
#endif //OP_HYBRID_GPU

void op_par_loop_time_step_kernel_gpu(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3,
  op_arg arg4);

//GPU host stub function
#if OP_HYBRID_GPU
void op_par_loop_time_step_kernel(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3,
  op_arg arg4){

  if (OP_hybrid_gpu) {
    op_par_loop_time_step_kernel_gpu(name, set,
      arg0,
      arg1,
      arg2,
      arg3,
      arg4);

    }else{
    op_par_loop_time_step_kernel_cpu(name, set,
      arg0,
      arg1,
      arg2,
      arg3,
      arg4);

  }
}
#else
void op_par_loop_time_step_kernel(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3,
  op_arg arg4){

  op_par_loop_time_step_kernel_gpu(name, set,
    arg0,
    arg1,
    arg2,
    arg3,
    arg4);

  }
#endif //OP_HYBRID_GPU

void op_par_loop_indirect_rw_kernel_gpu(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3,
  op_arg arg4);

//GPU host stub function
#if OP_HYBRID_GPU
void op_par_loop_indirect_rw_kernel(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3,
  op_arg arg4){

  if (OP_hybrid_gpu) {
    op_par_loop_indirect_rw_kernel_gpu(name, set,
      arg0,
      arg1,
      arg2,
      arg3,
      arg4);

    }else{
    op_par_loop_indirect_rw_kernel_cpu(name, set,
      arg0,
      arg1,
      arg2,
      arg3,
      arg4);

  }
}
#else
void op_par_loop_indirect_rw_kernel(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3,
  op_arg arg4){

  op_par_loop_indirect_rw_kernel_gpu(name, set,
    arg0,
    arg1,
    arg2,
    arg3,
    arg4);

  }
#endif //OP_HYBRID_GPU

void op_par_loop_residual_kernel_gpu(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2);

//GPU host stub function
#if OP_HYBRID_GPU
void op_par_loop_residual_kernel(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2){

  if (OP_hybrid_gpu) {
    op_par_loop_residual_kernel_gpu(name, set,
      arg0,
      arg1,
      arg2);

    }else{
    op_par_loop_residual_kernel_cpu(name, set,
      arg0,
      arg1,
      arg2);

  }
}
#else
void op_par_loop_residual_kernel(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2){

  op_par_loop_residual_kernel_gpu(name, set,
    arg0,
    arg1,
    arg2);

  }
#endif //OP_HYBRID_GPU

void op_par_loop_calc_rms_kernel_gpu(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1);

//GPU host stub function
#if OP_HYBRID_GPU
void op_par_loop_calc_rms_kernel(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1){

  if (OP_hybrid_gpu) {
    op_par_loop_calc_rms_kernel_gpu(name, set,
      arg0,
      arg1);

    }else{
    op_par_loop_calc_rms_kernel_cpu(name, set,
      arg0,
      arg1);

  }
}
#else
void op_par_loop_calc_rms_kernel(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1){

  op_par_loop_calc_rms_kernel_gpu(name, set,
    arg0,
    arg1);

  }
#endif //OP_HYBRID_GPU

void op_par_loop_count_bad_vals_gpu(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1);

//GPU host stub function
#if OP_HYBRID_GPU
void op_par_loop_count_bad_vals(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1){

  if (OP_hybrid_gpu) {
    op_par_loop_count_bad_vals_gpu(name, set,
      arg0,
      arg1);

    }else{
    op_par_loop_count_bad_vals_cpu(name, set,
      arg0,
      arg1);

  }
}
#else
void op_par_loop_count_bad_vals(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1){

  op_par_loop_count_bad_vals_gpu(name, set,
    arg0,
    arg1);

  }
#endif //OP_HYBRID_GPU

void op_par_loop_up_pre_kernel_gpu(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1);

//GPU host stub function
#if OP_HYBRID_GPU
void op_par_loop_up_pre_kernel(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1){

  if (OP_hybrid_gpu) {
    op_par_loop_up_pre_kernel_gpu(name, set,
      arg0,
      arg1);

    }else{
    op_par_loop_up_pre_kernel_cpu(name, set,
      arg0,
      arg1);

  }
}
#else
void op_par_loop_up_pre_kernel(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1){

  op_par_loop_up_pre_kernel_gpu(name, set,
    arg0,
    arg1);

  }
#endif //OP_HYBRID_GPU

void op_par_loop_up_kernel_gpu(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2);

//GPU host stub function
#if OP_HYBRID_GPU
void op_par_loop_up_kernel(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2){

  if (OP_hybrid_gpu) {
    op_par_loop_up_kernel_gpu(name, set,
      arg0,
      arg1,
      arg2);

    }else{
    op_par_loop_up_kernel_cpu(name, set,
      arg0,
      arg1,
      arg2);

  }
}
#else
void op_par_loop_up_kernel(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2){

  op_par_loop_up_kernel_gpu(name, set,
    arg0,
    arg1,
    arg2);

  }
#endif //OP_HYBRID_GPU

void op_par_loop_up_post_kernel_gpu(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1);

//GPU host stub function
#if OP_HYBRID_GPU
void op_par_loop_up_post_kernel(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1){

  if (OP_hybrid_gpu) {
    op_par_loop_up_post_kernel_gpu(name, set,
      arg0,
      arg1);

    }else{
    op_par_loop_up_post_kernel_cpu(name, set,
      arg0,
      arg1);

  }
}
#else
void op_par_loop_up_post_kernel(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1){

  op_par_loop_up_post_kernel_gpu(name, set,
    arg0,
    arg1);

  }
#endif //OP_HYBRID_GPU

void op_par_loop_down_v2_kernel_pre_gpu(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1);

//GPU host stub function
#if OP_HYBRID_GPU
void op_par_loop_down_v2_kernel_pre(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1){

  if (OP_hybrid_gpu) {
    op_par_loop_down_v2_kernel_pre_gpu(name, set,
      arg0,
      arg1);

    }else{
    op_par_loop_down_v2_kernel_pre_cpu(name, set,
      arg0,
      arg1);

  }
}
#else
void op_par_loop_down_v2_kernel_pre(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1){

  op_par_loop_down_v2_kernel_pre_gpu(name, set,
    arg0,
    arg1);

  }
#endif //OP_HYBRID_GPU

void op_par_loop_down_v2_kernel_gpu(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3,
  op_arg arg4,
  op_arg arg5,
  op_arg arg6,
  op_arg arg7,
  op_arg arg8,
  op_arg arg9);

//GPU host stub function
#if OP_HYBRID_GPU
void op_par_loop_down_v2_kernel(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3,
  op_arg arg4,
  op_arg arg5,
  op_arg arg6,
  op_arg arg7,
  op_arg arg8,
  op_arg arg9){

  if (OP_hybrid_gpu) {
    op_par_loop_down_v2_kernel_gpu(name, set,
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
      arg6,
      arg7,
      arg8,
      arg9);

    }else{
    op_par_loop_down_v2_kernel_cpu(name, set,
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
      arg6,
      arg7,
      arg8,
      arg9);

  }
}
#else
void op_par_loop_down_v2_kernel(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3,
  op_arg arg4,
  op_arg arg5,
  op_arg arg6,
  op_arg arg7,
  op_arg arg8,
  op_arg arg9){

  op_par_loop_down_v2_kernel_gpu(name, set,
    arg0,
    arg1,
    arg2,
    arg3,
    arg4,
    arg5,
    arg6,
    arg7,
    arg8,
    arg9);

  }
#endif //OP_HYBRID_GPU

void op_par_loop_down_v2_kernel_post_gpu(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3);

//GPU host stub function
#if OP_HYBRID_GPU
void op_par_loop_down_v2_kernel_post(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3){

  if (OP_hybrid_gpu) {
    op_par_loop_down_v2_kernel_post_gpu(name, set,
      arg0,
      arg1,
      arg2,
      arg3);

    }else{
    op_par_loop_down_v2_kernel_post_cpu(name, set,
      arg0,
      arg1,
      arg2,
      arg3);

  }
}
#else
void op_par_loop_down_v2_kernel_post(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3){

  op_par_loop_down_v2_kernel_post_gpu(name, set,
    arg0,
    arg1,
    arg2,
    arg3);

  }
#endif //OP_HYBRID_GPU

void op_par_loop_down_kernel_gpu(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3,
  op_arg arg4);

//GPU host stub function
#if OP_HYBRID_GPU
void op_par_loop_down_kernel(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3,
  op_arg arg4){

  if (OP_hybrid_gpu) {
    op_par_loop_down_kernel_gpu(name, set,
      arg0,
      arg1,
      arg2,
      arg3,
      arg4);

    }else{
    op_par_loop_down_kernel_cpu(name, set,
      arg0,
      arg1,
      arg2,
      arg3,
      arg4);

  }
}
#else
void op_par_loop_down_kernel(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2,
  op_arg arg3,
  op_arg arg4){

  op_par_loop_down_kernel_gpu(name, set,
    arg0,
    arg1,
    arg2,
    arg3,
    arg4);

  }
#endif //OP_HYBRID_GPU

void op_par_loop_identify_differences_gpu(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2);

//GPU host stub function
#if OP_HYBRID_GPU
void op_par_loop_identify_differences(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2){

  if (OP_hybrid_gpu) {
    op_par_loop_identify_differences_gpu(name, set,
      arg0,
      arg1,
      arg2);

    }else{
    op_par_loop_identify_differences_cpu(name, set,
      arg0,
      arg1,
      arg2);

  }
}
#else
void op_par_loop_identify_differences(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1,
  op_arg arg2){

  op_par_loop_identify_differences_gpu(name, set,
    arg0,
    arg1,
    arg2);

  }
#endif //OP_HYBRID_GPU

void op_par_loop_count_non_zeros_gpu(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1);

//GPU host stub function
#if OP_HYBRID_GPU
void op_par_loop_count_non_zeros(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1){

  if (OP_hybrid_gpu) {
    op_par_loop_count_non_zeros_gpu(name, set,
      arg0,
      arg1);

    }else{
    op_par_loop_count_non_zeros_cpu(name, set,
      arg0,
      arg1);

  }
}
#else
void op_par_loop_count_non_zeros(char const *name, op_set set,
  op_arg arg0,
  op_arg arg1){

  op_par_loop_count_non_zeros_gpu(name, set,
    arg0,
    arg1);

  }
#endif //OP_HYBRID_GPU
#endif
